{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7490cb47-2bed-4708-8469-40aa5cab5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIPT FROM PYTHON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "923cc8bf-4662-40db-a3ba-3c77e0536bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Paweł\\AppData\\Local\\Temp\\ipykernel_12940\\146039444.py:9: ParserWarning: Skipping line 878: expected 11 fields, saw 12\n",
      "Skipping line 1713: expected 11 fields, saw 12\n",
      "Skipping line 1815: expected 11 fields, saw 12\n",
      "Skipping line 2858: expected 11 fields, saw 12\n",
      "Skipping line 3734: expected 11 fields, saw 12\n",
      "Skipping line 4756: expected 11 fields, saw 12\n",
      "Skipping line 5389: expected 11 fields, saw 12\n",
      "Skipping line 5423: expected 11 fields, saw 12\n",
      "Skipping line 5614: expected 11 fields, saw 12\n",
      "Skipping line 5849: expected 11 fields, saw 12\n",
      "Skipping line 6093: expected 11 fields, saw 12\n",
      "Skipping line 7516: expected 11 fields, saw 12\n",
      "Skipping line 7626: expected 11 fields, saw 12\n",
      "Skipping line 8893: expected 11 fields, saw 12\n",
      "Skipping line 9015: expected 11 fields, saw 12\n",
      "Skipping line 9571: expected 11 fields, saw 12\n",
      "Skipping line 9620: expected 11 fields, saw 12\n",
      "Skipping line 9751: expected 11 fields, saw 12\n",
      "Skipping line 10157: expected 11 fields, saw 12\n",
      "Skipping line 10427: expected 11 fields, saw 12\n",
      "Skipping line 12035: expected 11 fields, saw 12\n",
      "Skipping line 12113: expected 11 fields, saw 12\n",
      "Skipping line 12144: expected 11 fields, saw 12\n",
      "Skipping line 12891: expected 11 fields, saw 12\n",
      "Skipping line 14613: expected 11 fields, saw 12\n",
      "Skipping line 16031: expected 11 fields, saw 12\n",
      "Skipping line 16344: expected 11 fields, saw 12\n",
      "Skipping line 16399: expected 11 fields, saw 12\n",
      "Skipping line 16635: expected 11 fields, saw 12\n",
      "Skipping line 16722: expected 11 fields, saw 12\n",
      "Skipping line 18241: expected 11 fields, saw 12\n",
      "Skipping line 18367: expected 11 fields, saw 12\n",
      "Skipping line 18479: expected 11 fields, saw 12\n",
      "Skipping line 19814: expected 11 fields, saw 12\n",
      "Skipping line 19859: expected 11 fields, saw 12\n",
      "Skipping line 19909: expected 11 fields, saw 12\n",
      "Skipping line 19935: expected 11 fields, saw 12\n",
      "Skipping line 20386: expected 11 fields, saw 12\n",
      "Skipping line 20533: expected 11 fields, saw 12\n",
      "Skipping line 20764: expected 11 fields, saw 12\n",
      "Skipping line 21145: expected 11 fields, saw 12\n",
      "Skipping line 21291: expected 11 fields, saw 12\n",
      "Skipping line 21309: expected 11 fields, saw 12\n",
      "Skipping line 21576: expected 11 fields, saw 12\n",
      "Skipping line 21966: expected 11 fields, saw 12\n",
      "Skipping line 22092: expected 11 fields, saw 12\n",
      "Skipping line 22108: expected 11 fields, saw 12\n",
      "Skipping line 22236: expected 11 fields, saw 12\n",
      "Skipping line 22785: expected 11 fields, saw 12\n",
      "Skipping line 23143: expected 11 fields, saw 12\n",
      "Skipping line 23145: expected 11 fields, saw 12\n",
      "Skipping line 23251: expected 11 fields, saw 12\n",
      "Skipping line 23369: expected 11 fields, saw 12\n",
      "Skipping line 23464: expected 11 fields, saw 12\n",
      "Skipping line 23622: expected 11 fields, saw 12\n",
      "Skipping line 23732: expected 11 fields, saw 12\n",
      "Skipping line 23924: expected 11 fields, saw 12\n",
      "Skipping line 24696: expected 11 fields, saw 12\n",
      "Skipping line 25543: expected 11 fields, saw 12\n",
      "Skipping line 25703: expected 11 fields, saw 12\n",
      "Skipping line 25815: expected 11 fields, saw 12\n",
      "Skipping line 26185: expected 11 fields, saw 12\n",
      "Skipping line 27424: expected 11 fields, saw 12\n",
      "Skipping line 27465: expected 11 fields, saw 12\n",
      "Skipping line 28083: expected 11 fields, saw 12\n",
      "Skipping line 28282: expected 11 fields, saw 12\n",
      "Skipping line 28460: expected 11 fields, saw 12\n",
      "Skipping line 28745: expected 11 fields, saw 12\n",
      "Skipping line 29674: expected 11 fields, saw 12\n",
      "Skipping line 30342: expected 11 fields, saw 12\n",
      "Skipping line 30417: expected 11 fields, saw 12\n",
      "Skipping line 31154: expected 11 fields, saw 12\n",
      "Skipping line 31308: expected 11 fields, saw 12\n",
      "Skipping line 32198: expected 11 fields, saw 12\n",
      "Skipping line 32439: expected 11 fields, saw 12\n",
      "Skipping line 32675: expected 11 fields, saw 12\n",
      "Skipping line 33134: expected 11 fields, saw 12\n",
      "Skipping line 33442: expected 11 fields, saw 12\n",
      "Skipping line 34184: expected 11 fields, saw 12\n",
      "Skipping line 34731: expected 11 fields, saw 12\n",
      "Skipping line 34869: expected 11 fields, saw 12\n",
      "Skipping line 35107: expected 11 fields, saw 12\n",
      "Skipping line 35300: expected 11 fields, saw 12\n",
      "Skipping line 35396: expected 11 fields, saw 12\n",
      "Skipping line 35913: expected 11 fields, saw 12\n",
      "Skipping line 36445: expected 11 fields, saw 12\n",
      "Skipping line 36693: expected 11 fields, saw 12\n",
      "Skipping line 36723: expected 11 fields, saw 12\n",
      "Skipping line 37293: expected 11 fields, saw 12\n",
      "Skipping line 37361: expected 11 fields, saw 12\n",
      "Skipping line 37980: expected 11 fields, saw 12\n",
      "Skipping line 38090: expected 11 fields, saw 12\n",
      "Skipping line 38197: expected 11 fields, saw 12\n",
      "Skipping line 39431: expected 11 fields, saw 12\n",
      "Skipping line 39598: expected 11 fields, saw 12\n",
      "Skipping line 39679: expected 11 fields, saw 12\n",
      "Skipping line 39794: expected 11 fields, saw 12\n",
      "Skipping line 40021: expected 11 fields, saw 12\n",
      "Skipping line 40430: expected 11 fields, saw 12\n",
      "Skipping line 42858: expected 11 fields, saw 12\n",
      "Skipping line 43662: expected 11 fields, saw 12\n",
      "Skipping line 44162: expected 11 fields, saw 12\n",
      "Skipping line 45529: expected 11 fields, saw 12\n",
      "Skipping line 46678: expected 11 fields, saw 12\n",
      "Skipping line 46788: expected 11 fields, saw 12\n",
      "Skipping line 46811: expected 11 fields, saw 12\n",
      "Skipping line 46924: expected 11 fields, saw 12\n",
      "Skipping line 47287: expected 11 fields, saw 12\n",
      "Skipping line 47377: expected 11 fields, saw 12\n",
      "Skipping line 47419: expected 11 fields, saw 12\n",
      "Skipping line 47492: expected 11 fields, saw 12\n",
      "Skipping line 47629: expected 11 fields, saw 12\n",
      "Skipping line 48125: expected 11 fields, saw 12\n",
      "Skipping line 48932: expected 11 fields, saw 12\n",
      "Skipping line 48971: expected 11 fields, saw 12\n",
      "Skipping line 49440: expected 11 fields, saw 12\n",
      "Skipping line 49457: expected 11 fields, saw 12\n",
      "Skipping line 50670: expected 11 fields, saw 12\n",
      "Skipping line 50960: expected 11 fields, saw 12\n",
      "Skipping line 51275: expected 11 fields, saw 12\n",
      "Skipping line 51649: expected 11 fields, saw 12\n",
      "Skipping line 51993: expected 11 fields, saw 12\n",
      "Skipping line 52023: expected 11 fields, saw 12\n",
      "Skipping line 52059: expected 11 fields, saw 12\n",
      "Skipping line 52259: expected 11 fields, saw 12\n",
      "Skipping line 52368: expected 11 fields, saw 12\n",
      "Skipping line 52783: expected 11 fields, saw 12\n",
      "Skipping line 53064: expected 11 fields, saw 12\n",
      "Skipping line 53135: expected 11 fields, saw 12\n",
      "Skipping line 53514: expected 11 fields, saw 12\n",
      "Skipping line 54092: expected 11 fields, saw 12\n",
      "Skipping line 55403: expected 11 fields, saw 12\n",
      "Skipping line 57476: expected 11 fields, saw 12\n",
      "Skipping line 58646: expected 11 fields, saw 12\n",
      "Skipping line 58808: expected 11 fields, saw 12\n",
      "Skipping line 59119: expected 11 fields, saw 12\n",
      "Skipping line 59727: expected 11 fields, saw 12\n",
      "Skipping line 60386: expected 11 fields, saw 12\n",
      "Skipping line 60478: expected 11 fields, saw 12\n",
      "Skipping line 60542: expected 11 fields, saw 12\n",
      "Skipping line 60913: expected 11 fields, saw 12\n",
      "Skipping line 61032: expected 11 fields, saw 12\n",
      "Skipping line 61640: expected 11 fields, saw 12\n",
      "Skipping line 61732: expected 11 fields, saw 12\n",
      "Skipping line 62029: expected 11 fields, saw 12\n",
      "Skipping line 62219: expected 11 fields, saw 12\n",
      "Skipping line 63657: expected 11 fields, saw 12\n",
      "Skipping line 64712: expected 11 fields, saw 12\n",
      "\n",
      "  dataframe = pd.read_csv(r'C:\\Repos\\ufo_project\\data\\source_files\\complete.csv',sep=',',on_bad_lines='warn')\n",
      "C:\\Users\\Paweł\\AppData\\Local\\Temp\\ipykernel_12940\\146039444.py:9: ParserWarning: Skipping line 65881: expected 11 fields, saw 12\n",
      "Skipping line 66093: expected 11 fields, saw 12\n",
      "Skipping line 66095: expected 11 fields, saw 12\n",
      "Skipping line 66476: expected 11 fields, saw 12\n",
      "Skipping line 66549: expected 11 fields, saw 12\n",
      "Skipping line 66550: expected 11 fields, saw 12\n",
      "Skipping line 68102: expected 11 fields, saw 12\n",
      "Skipping line 69441: expected 11 fields, saw 12\n",
      "Skipping line 70104: expected 11 fields, saw 12\n",
      "Skipping line 70452: expected 11 fields, saw 12\n",
      "Skipping line 70642: expected 11 fields, saw 12\n",
      "Skipping line 70644: expected 11 fields, saw 12\n",
      "Skipping line 70716: expected 11 fields, saw 12\n",
      "Skipping line 71345: expected 11 fields, saw 12\n",
      "Skipping line 71634: expected 11 fields, saw 12\n",
      "Skipping line 72091: expected 11 fields, saw 12\n",
      "Skipping line 72119: expected 11 fields, saw 12\n",
      "Skipping line 73543: expected 11 fields, saw 12\n",
      "Skipping line 74654: expected 11 fields, saw 12\n",
      "Skipping line 74785: expected 11 fields, saw 12\n",
      "Skipping line 74918: expected 11 fields, saw 12\n",
      "Skipping line 75062: expected 11 fields, saw 12\n",
      "Skipping line 75346: expected 11 fields, saw 12\n",
      "Skipping line 75416: expected 11 fields, saw 12\n",
      "Skipping line 75677: expected 11 fields, saw 12\n",
      "Skipping line 75833: expected 11 fields, saw 12\n",
      "Skipping line 76117: expected 11 fields, saw 12\n",
      "Skipping line 76834: expected 11 fields, saw 12\n",
      "Skipping line 77540: expected 11 fields, saw 12\n",
      "Skipping line 77568: expected 11 fields, saw 12\n",
      "Skipping line 77607: expected 11 fields, saw 12\n",
      "Skipping line 77871: expected 11 fields, saw 12\n",
      "Skipping line 78117: expected 11 fields, saw 12\n",
      "Skipping line 78526: expected 11 fields, saw 12\n",
      "Skipping line 78605: expected 11 fields, saw 12\n",
      "Skipping line 79151: expected 11 fields, saw 12\n",
      "Skipping line 79945: expected 11 fields, saw 12\n",
      "Skipping line 80156: expected 11 fields, saw 12\n",
      "Skipping line 80328: expected 11 fields, saw 12\n",
      "Skipping line 80382: expected 11 fields, saw 12\n",
      "Skipping line 80421: expected 11 fields, saw 12\n",
      "Skipping line 80503: expected 11 fields, saw 12\n",
      "Skipping line 82071: expected 11 fields, saw 12\n",
      "Skipping line 82566: expected 11 fields, saw 12\n",
      "Skipping line 86123: expected 11 fields, saw 12\n",
      "Skipping line 87218: expected 11 fields, saw 12\n",
      "Skipping line 87457: expected 11 fields, saw 12\n",
      "Skipping line 87579: expected 11 fields, saw 12\n",
      "\n",
      "  dataframe = pd.read_csv(r'C:\\Repos\\ufo_project\\data\\source_files\\complete.csv',sep=',',on_bad_lines='warn')\n",
      "C:\\Users\\Paweł\\AppData\\Local\\Temp\\ipykernel_12940\\146039444.py:9: DtypeWarning: Columns (5,9) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dataframe = pd.read_csv(r'C:\\Repos\\ufo_project\\data\\source_files\\complete.csv',sep=',',on_bad_lines='warn')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import re\n",
    "import functools as fc\n",
    "import pycountry\n",
    "\n",
    "# Loading data to file\n",
    "countries = pd.read_csv(r'C:\\Repos\\ufo_project\\data\\additional_files\\countries.csv',sep=',')\n",
    "dataframe = pd.read_csv(r'C:\\Repos\\ufo_project\\data\\source_files\\complete.csv',sep=',',on_bad_lines='warn')\n",
    "\n",
    "# countries dataframe preparing for merge\n",
    "countries['name'] = countries['name'].astype('str')\n",
    "countries['name'] = countries['name'].str.lower()\n",
    "countries['code'] = countries['code'].str.lower()\n",
    "countries['filled_country'] = countries['name']\n",
    "\n",
    "# Functions for data conversions\n",
    "# Filter data to be only numbers, dots and comma\n",
    "def regex_match(a):\n",
    "    if re.search(\"[0123456789,.]\", a):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# If array empty paste dummy data\n",
    "def check_if_array_empty(a):\n",
    "    if len(a) > 0:\n",
    "        return a\n",
    "    else:\n",
    "        return ['0','.','0']\n",
    "\n",
    "# Check if cell contains string, if yes return value\n",
    "def country_check(a,string,value):\n",
    "    if string in a:\n",
    "        return value\n",
    "    else:\n",
    "        return a\n",
    "\n",
    "#funkcja do wyszukania nazwy kraju po country_id przy użyciu ISC code\n",
    "def get_country_name(iso_code):\n",
    "    if isinstance(iso_code, str):  # Sprawdzamy, czy kod jest łańcuchem znaków\n",
    "        try:\n",
    "            iso_code = iso_code.upper()\n",
    "            country = pycountry.countries.get(alpha_2=iso_code)\n",
    "            return country.name if country else None\n",
    "        except KeyError:\n",
    "            return None\n",
    "    else:\n",
    "        return None  # Dla NaN i innych nieprawidłowych danych zwracamy None\n",
    "\n",
    "def get_country_code(name):\n",
    "    try:\n",
    "        return pycountry.countries.lookup(name).alpha_2  # Zwraca kod ISO alpha_2 (np. 'PL')\n",
    "    except LookupError:\n",
    "        return None  # Jeśli nie znajdzie kraju, zwraca None\n",
    "\n",
    "# Datetime column cleanups\n",
    "dataframe['date_changes'] = dataframe['datetime'].str.split(\" \")\n",
    "dataframe['new_date'] = dataframe['date_changes'].apply(lambda a: a[0])\n",
    "dataframe['new_hour'] = dataframe['date_changes'].apply(lambda a: a[1])\n",
    "dataframe['new_hour'] = dataframe['new_hour'].apply(lambda a: a + ':00')\n",
    "dataframe['new_date'] = dataframe['new_date'].astype('datetime64[ns]')\n",
    "dataframe['new_hour'] = dataframe['new_hour'].astype('timedelta64[ns]')\n",
    "dataframe['hour_cleaned'] = dataframe['new_hour'].mask(dataframe['new_hour'] >= dt.timedelta(hours=24), dataframe['new_hour'] - dt.timedelta(hours=24))\n",
    "dataframe['final_date'] = dataframe['new_date'] + dataframe['hour_cleaned']\n",
    "dataframe['datetime'] = dataframe['final_date']\n",
    "dataframe = dataframe.drop(columns = ['date_changes','new_date','new_hour','hour_cleaned','final_date'])\n",
    "\n",
    "# Changing types of clomuns which don't need cleanup\n",
    "dataframe['date posted'] = dataframe['date posted'].astype('datetime64[ns]')\n",
    "dataframe['comments'] = dataframe['comments'].astype('str')\n",
    "\n",
    "# Latitude column cleanups\n",
    "dataframe['latitude'] = dataframe['latitude'].astype('str')\n",
    "dataframe['latitude'] = dataframe['latitude'].str.strip()\n",
    "dataframe['lat_splited'] = dataframe['latitude'].str.split('')\n",
    "dataframe['lat_filtered'] = dataframe['lat_splited'].apply(\n",
    "    lambda x: list(filter(\n",
    "        lambda a:  regex_match(a),x\n",
    "    ))\n",
    ")\n",
    "dataframe['lat_final'] = dataframe['lat_filtered'].apply(\n",
    "    lambda x: fc.reduce(\n",
    "        lambda a,b: a+b,x)\n",
    ")\n",
    "dataframe['lat_final'] = dataframe['lat_final'].astype('float')\n",
    "dataframe['latitude'] = dataframe['lat_final']\n",
    "\n",
    "\n",
    "# Duration column cleanups\n",
    "dataframe['duration (seconds)'] = dataframe['duration (seconds)'].astype('str')\n",
    "dataframe['duration (seconds)'] = dataframe['duration (seconds)'].str.strip()\n",
    "dataframe['dur_splited'] = dataframe['duration (seconds)'].str.split('')\n",
    "dataframe['dur_filtered'] = dataframe['dur_splited'].apply(\n",
    "    lambda x: list(filter(\n",
    "        lambda a:  regex_match(a),x\n",
    "    ))\n",
    ")\n",
    "dataframe['dur_filtered'] = dataframe['dur_filtered'].apply(lambda x: check_if_array_empty(x))\n",
    "dataframe['dur_final'] = dataframe['dur_filtered'].apply(\n",
    "    lambda x: fc.reduce(\n",
    "        lambda a,b: a+b,x)\n",
    ")\n",
    "dataframe['duration (seconds)'] = dataframe['dur_final']\n",
    "dataframe['duration (seconds)'] = dataframe['duration (seconds)'].astype('float')\n",
    "dataframe = dataframe.drop(columns = ['lat_splited','lat_filtered','lat_final','dur_splited','dur_filtered','dur_final'])\n",
    "\n",
    "\n",
    "# countries column filling with data from cities\n",
    "dataframe['state_check'] = dataframe['state'].isnull()\n",
    "dataframe['country_check'] = dataframe['country'].isnull()\n",
    "\n",
    "t_df = dataframe.copy()\n",
    "t_df = t_df[t_df['country_check'] == True]\n",
    "t_df['city'] = t_df['city'].astype('str')\n",
    "t_df['city'] = t_df['city'].str.strip()\n",
    "t_df['city_new'] = t_df['city'].str.split('(')\n",
    "t_df['filtr'] = t_df['city_new'].apply(lambda a: len(a) > 1)\n",
    "t_df = t_df[t_df['filtr'] == True ]\n",
    "t_df['filled_country'] = t_df['city_new'].apply(lambda a: a[max(len(a)-1,0)])\n",
    "t_df['filled_country'] = t_df['filled_country'].astype('str')\n",
    "t_df['filled_country'] = t_df['filled_country'].str.rstrip(')')\n",
    "t_df['filled_country'] = t_df['filled_country'].str.lower()\n",
    "t_df['filled_country'] = t_df['filled_country'].apply(lambda a: country_check(a,'uk/','united kingdom'))\n",
    "t_df['filled_country'] = t_df['filled_country'].apply(lambda a: country_check(a,'australia','australia') )\n",
    "\n",
    "# merging with countires table \n",
    "result = pd.merge(t_df,countries,on='filled_country',how='left')\n",
    "result['check'] = result['name'].isnull()\n",
    "result['country'] = result['code']\n",
    "result = result.drop(columns=['city_new','filtr','filled_country','id','code','name','continent','check'])\n",
    "\n",
    "result['country_check'] = result['country'].isnull()\n",
    "result_2 = result.copy()\n",
    "result_2 = result_2[result_2['country_check']== True]\n",
    "result_2 = result_2[result_2['state_check']==False]\n",
    "result_2['country'] = 'us'\n",
    "\n",
    "result = result[result['country_check'] == False]\n",
    "final = pd.concat([result,result_2])\n",
    "\n",
    "# final merge after filling columns\n",
    "m_df = pd.merge(dataframe,final, on=['datetime','city','duration (seconds)','state','shape','duration (hours/min)','comments','date posted','latitude','longitude','state_check'],how='left')\n",
    "m_df['country_x'] = m_df['country_x'].mask(m_df['country_check_y'] == False,m_df['country_y'])\n",
    "m_df = m_df.drop(columns=['state_check','country_check_x','country_y','country_check_y'])\n",
    "m_df = m_df.rename(columns={'country_x':'country'})\n",
    "\n",
    "# filling null countires with state entry with 'us'\n",
    "m_df['country_check'] = m_df['country'].isnull()\n",
    "m_df['state_check'] = m_df['state'].isnull()\n",
    "m_df_2 = m_df.copy()\n",
    "m_df = m_df[m_df['country_check']== False]\n",
    "m_df_2 = m_df_2[m_df_2['country_check']== True]\n",
    "m_df_2['country'] = m_df_2['country'].mask(m_df_2['state_check']==False,'us')\n",
    "m_df = pd.concat([m_df,m_df_2])\n",
    "m_df = m_df.sort_index()\n",
    "m_df['country_check'] = m_df['country'].isnull()\n",
    "m_df = m_df.drop(columns=['country_check','state_check'])\n",
    "\n",
    "\n",
    "# shape column cleanups\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'flare','light')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'round','sphere')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'delta','triangle')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'pyramid','triangle')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'changed','changing')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'disk','circle')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'flash','light')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'teardrop','oval')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'egg','oval')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'unknown','other')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'hexagon','other')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'crescent','other')\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape'] == 'dome','other')\n",
    "m_df['shape_check'] = m_df['shape'].isnull()\n",
    "m_df['shape'] = m_df['shape'].mask(m_df['shape_check'] == True,'other')\n",
    "m_df['shape_check'] = m_df['shape'].isnull()\n",
    "m_df = m_df.drop(columns=['shape_check'])\n",
    "\n",
    "# Renaming columns, preparing to save final files\n",
    "m_df = m_df.rename(columns={'datetime':'observation_datestamp','country':'country_id','shape':'shape_type','duration (seconds)':'duration_in_sec','duration (hours/min)':'duration_string','state':'state_id','date posted':'date_posted'})\n",
    "\n",
    "# Saving of first version of files\n",
    "# m_df.to_csv(r'data/complete_cleaned.csv',sep=';')\n",
    "# m_df.to_parquet(r'data/complete_cleaned.parquet')\n",
    "\n",
    "m_df[\"observation_datestamp\"] = pd.to_datetime(m_df[\"observation_datestamp\"])\n",
    "m_df['date']=m_df['observation_datestamp'].dt.date\n",
    "\n",
    "# adding year column\n",
    "m_df['date']=pd.to_datetime(m_df['date'],format=\"%Y-%m-%d\")\n",
    "m_df['year'] = m_df['date'].dt.year\n",
    "m_df.drop(columns=\"observation_datestamp\",inplace=True)\n",
    "\n",
    "m_df['state_id']=m_df['state_id'].str.upper()\n",
    "m_df['country_id']=m_df['country_id'].str.upper()\n",
    "m_df['city']=m_df['city'].str.title()\n",
    "\n",
    "#usuwanie nawiasow wraz z zawartoscia\n",
    "m_df['city'] = m_df['city'].str.replace(r'\\(.*?\\)', '', regex=True)\n",
    "\n",
    "#usuwanie nawiasów otwierających wraz z zawartoscia\n",
    "m_df['city'] = m_df['city'].str.replace(r'\\(.*?', '', regex=True)\n",
    "\n",
    "#ręczna poprawa powyższych danych\n",
    "m_df.loc[8194,'country_id']='CA'\n",
    "m_df.loc[5789,'city']='Unadilla'\n",
    "m_df.loc[8194,'city']='Ft. Resolution'\n",
    "m_df.loc[40609,'city']='Tel Aviv'\n",
    "m_df.loc[40609,'country_id']='IL'\n",
    "m_df.loc[52860,'city']='London'\n",
    "m_df.loc[52860,'country_id']='GB'  \n",
    "m_df.loc[45133,'city']='Iowa City'\n",
    "m_df.loc[54713, 'city']='Phuket'\n",
    "m_df.loc[54713, 'country_id']='TH'\n",
    "m_df.loc[60128, 'city']=''\n",
    "m_df.loc[60128, 'country_id']='AFG'\n",
    "m_df.loc[75757,'city']=''   \n",
    "m_df.loc[78575,'city']=''\n",
    "m_df.loc[80683,'city']='Midwest'\n",
    "m_df.loc[80683,'country_id']='US'\n",
    "\n",
    "#usuwanie nawiasow zamykających + spacji przed\n",
    "m_df['city'] = m_df['city'].str.replace(r' \\)', '', regex=True)\n",
    "\n",
    "#usuwanie nawiasow zamykających bez spacji\n",
    "m_df['city'] = m_df['city'].str.replace(r'\\)', '', regex=True)\n",
    "\n",
    "m_df['city'] = m_df['city'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "m_df['city'] = m_df['city'].str.replace(r'\\bNas\\b', '', regex=True)\n",
    "\n",
    "#nowa kolumna country_name, która korzysta z funkcji get_country_name\n",
    "m_df['country_name'] = m_df['country_id'].apply(get_country_name)\n",
    "\n",
    "#gdy country_name jest puste, dodajemy info z city\n",
    "m_df['country_name'] = m_df['country_name'].fillna(m_df['city'])\n",
    "\n",
    "m_df['id'] = m_df.index + 1\n",
    "\n",
    "new_order = ['id','date','year','city','state_id','country_id','country_name','shape_type','duration_in_sec','duration_string','comments','date_posted','latitude','longitude']\n",
    "m_df = m_df[new_order]\n",
    "\n",
    "#usunięcie niewidzialnych znaków z country_name\n",
    "m_df['country_name'] = m_df['country_name'].str.strip().str.replace(r'\\s+', ' ', regex=True)\n",
    "\n",
    "#usuwanie znaków znaków innych niż Literowe\n",
    "m_df= m_df[~m_df['city'].str.contains(r'[^a-zA-Z\\s]', na=False)]\n",
    "\n",
    "#usuwanie znaków zapytania\n",
    "m_df= m_df[~m_df['city'].str.contains(r'\\?', na=False)]\n",
    "\n",
    "# Uzupełnianie brakujących wartości w kolumnie country_id\n",
    "m_df['country_id'] = m_df.apply(\n",
    "    lambda row: get_country_code(row['country_name']) if pd.isna(row['country_id']) else row['country_id'],\n",
    "    axis=1)\n",
    "\n",
    "#usuwanie pozycji gdzie country_id nie zostało uzupełnione\n",
    "m_df= m_df.dropna(subset=['country_id'])\n",
    "\n",
    "reg_df=pd.read_csv(r\"C:\\Repos\\ufo_project\\data\\final_file\\regions.csv\",\n",
    "                sep=\",\",\n",
    "                header=0\n",
    "                  )\n",
    "\n",
    "df_merged=m_df.merge(right=reg_df,how='left',left_on='country_id',right_on='alpha-2')\n",
    "\n",
    "df_merged.drop(columns=\"country-code\",inplace=True)\n",
    "df_merged.drop(columns=\"iso_3166-2\",inplace=True)\n",
    "df_merged.drop(columns=\"intermediate-region\",inplace=True)\n",
    "df_merged.drop(columns=\"region-code\",inplace=True)\n",
    "df_merged.drop(columns=\"sub-region-code\",inplace=True)\n",
    "df_merged.drop(columns=\"intermediate-region-code\",inplace=True)\n",
    "\n",
    "cleared_data = df_merged\n",
    "\n",
    "cleared_data.to_csv(r\"C:\\Repos\\ufo_project\\data\\cleared_data_py.csv\",index=False)\n",
    "cleared_data.to_parquet(r\"C:\\Repos\\ufo_project\\data\\cleared_data_py.parquet\",index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd8d6714-bd51-48e9-b9d0-9dd799f1e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_1 = pd.read_parquet(r\"C:\\Repos\\ufo_project\\data\\cleared_data.parquet\")\n",
    "df_test_2 = pd.read_parquet(r\"C:\\Repos\\ufo_project\\data\\cleared_data_py.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96a0241e-b5b4-4012-8230-11ae04302bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84057 entries, 0 to 84056\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   id               84057 non-null  int64         \n",
      " 1   date             84057 non-null  datetime64[ns]\n",
      " 2   year             84057 non-null  int32         \n",
      " 3   city             84057 non-null  object        \n",
      " 4   state_id         78038 non-null  object        \n",
      " 5   country_id       84057 non-null  object        \n",
      " 6   country_name     84057 non-null  object        \n",
      " 7   shape_type       84057 non-null  object        \n",
      " 8   duration_in_sec  84057 non-null  float64       \n",
      " 9   duration_string  81212 non-null  object        \n",
      " 10  comments         84057 non-null  object        \n",
      " 11  date_posted      84057 non-null  datetime64[ns]\n",
      " 12  latitude         84057 non-null  float64       \n",
      " 13  longitude        84057 non-null  float64       \n",
      " 14  name             84050 non-null  object        \n",
      " 15  alpha-2          84050 non-null  object        \n",
      " 16  alpha-3          84050 non-null  object        \n",
      " 17  region           84049 non-null  object        \n",
      " 18  sub-region       84049 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(3), int32(1), int64(1), object(12)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test_1.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1267c28d-0308-45e6-8548-1be87303e910",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84057 entries, 0 to 84056\n",
      "Data columns (total 19 columns):\n",
      " #   Column           Non-Null Count  Dtype         \n",
      "---  ------           --------------  -----         \n",
      " 0   id               84057 non-null  int64         \n",
      " 1   date             84057 non-null  datetime64[ns]\n",
      " 2   year             84057 non-null  int32         \n",
      " 3   city             84057 non-null  object        \n",
      " 4   state_id         78038 non-null  object        \n",
      " 5   country_id       84057 non-null  object        \n",
      " 6   country_name     84057 non-null  object        \n",
      " 7   shape_type       84057 non-null  object        \n",
      " 8   duration_in_sec  84057 non-null  float64       \n",
      " 9   duration_string  81212 non-null  object        \n",
      " 10  comments         84057 non-null  object        \n",
      " 11  date_posted      84057 non-null  datetime64[ns]\n",
      " 12  latitude         84057 non-null  float64       \n",
      " 13  longitude        84057 non-null  float64       \n",
      " 14  name             84050 non-null  object        \n",
      " 15  alpha-2          84050 non-null  object        \n",
      " 16  alpha-3          84050 non-null  object        \n",
      " 17  region           84049 non-null  object        \n",
      " 18  sub-region       84049 non-null  object        \n",
      "dtypes: datetime64[ns](2), float64(3), int32(1), int64(1), object(12)\n",
      "memory usage: 11.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test_2.info(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae6c5c9b-f7c4-4bea-95e4-ce9f283b612b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_2.equals(df_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc980b89-ff44-48b4-b4d4-fe02fc32d5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
